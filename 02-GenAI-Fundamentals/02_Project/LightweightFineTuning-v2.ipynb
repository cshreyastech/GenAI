{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f0a19",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db47fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q \"datasets==2.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f9bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/student/.local/lib/python3.10/site-packages (4.57.0)\n",
      "Requirement already satisfied: accelerate in /home/student/.local/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: peft in /home/student/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/student/.local/lib/python3.10/site-packages (0.48.1)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/student/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/student/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: requests in /home/student/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/student/.local/lib/python3.10/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/student/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (65.6.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.local/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64fbec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bc6957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    # BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "root_dir = \"./tmp\"\n",
    "# root_dir = \"./../../../../data/GenAI/02_genai_fundamentals/project2/results\"\n",
    "\n",
    "training_artifacts_dir = 'training_artifacts'\n",
    "archive_zip = 'archive'\n",
    "\n",
    "foundation_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "foundation_model_path = os.path.join(root_dir, training_artifacts_dir, \"foundation_model\", \"model\")\n",
    "foundation_model_output_path = os.path.join(root_dir, training_artifacts_dir, \"foundation_model\", \"output\")\n",
    "\n",
    "\n",
    "lora_model_path = os.path.join(root_dir, \"lora_model\", \"model\")\n",
    "lora_model_output_path = os.path.join(root_dir, \"lora_model\", \"output\")\n",
    "\n",
    "qlora_model_path = os.path.join(root_dir, \"qlora_model\", \"model\")\n",
    "qlora_model_output_path = os.path.join(root_dir, \"qlora_model\", \"output\")\n",
    "                                \n",
    "                                \n",
    "batch_size = 16\n",
    "train_epochs = 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa805616",
   "metadata": {},
   "source": [
    "## Clearn up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4b7c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder './tmp' and its contents deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Check if the folder exists before attempting to delete\n",
    "folder_to_delete = root_dir\n",
    "if os.path.exists(folder_to_delete):\n",
    "    try:\n",
    "        shutil.rmtree(folder_to_delete)\n",
    "        print(f\"Folder '{folder_to_delete}' and its contents deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {folder_to_delete} : {e.strerror}\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_to_delete}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2ab64",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5077e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"sms_spam\", split=\"train\")\n",
    "# dataset = dataset.select(range(3))\n",
    "\n",
    "# dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=23)\n",
    "\n",
    "\n",
    "# splits = [\"train\", \"test\"]\n",
    "\n",
    "# # View the dataset characteristics\n",
    "# dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8846b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sms': 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first example\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ad30c",
   "metadata": {},
   "source": [
    "## Pre-process datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39994a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa8716c8b6c4f6c83fc21806545fc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d189a0f8fcc4447eaa914f528a4f7ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(foundation_model_name)\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbd66c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "foundation_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    foundation_model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "\n",
    "# Unfreeze all the model parameters.\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in foundation_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(foundation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c8046f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f011867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAndValidate(model, model_output_path, model_path):\n",
    "    model.to(device)\n",
    "    \n",
    "    # Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=model_output_path,\n",
    "            # Set the learning rate\n",
    "            learning_rate=2e-5,\n",
    "            # Set the per device train batch size and eval batch size\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            # Evaluate and save the model after each epoch\n",
    "            # evaluation_strategy=\"epoch\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            num_train_epochs=train_epochs,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "        ),\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    \n",
    "    model.to(device)\n",
    "    trainer.evaluate()\n",
    "    \n",
    "    print(\"saving model\", model_path)\n",
    "    model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860408d",
   "metadata": {},
   "source": [
    "## Train Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1163f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_504/601428653.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.042949</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.987444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model ./tmp/training_artifacts/foundation_model/model\n"
     ]
    }
   ],
   "source": [
    "TrainAndValidate(foundation_model, foundation_model_output_path, foundation_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00268b",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc84927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foundation_model.to(device)\n",
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6031b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e02a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foundation_model.save_pretrained(foundation_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_504/601428653.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 00:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.044815</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model ./tmp/lora_model/model\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(foundation_model, lora_config)\n",
    "\n",
    "# lora_model.print_trainable_parameters()\n",
    "\n",
    "lora_trainer = TrainAndValidate(lora_model, lora_model_output_path, lora_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the model\n",
    "# lora_model.save_pretrained(lora_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f041cd",
   "metadata": {},
   "source": [
    "## Performing Bits and Bytes\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b18a2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fd9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qlora_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     foundation_model_name,\n",
    "#     num_labels=2,\n",
    "#     quantization_config=bnb_config,\n",
    "#     # device_map=\"auto\",   # automatically place modules on GPU\n",
    "#     id2label={0: \"not spam\", 1: \"spam\"},\n",
    "#     label2id={\"not spam\": 0, \"spam\": 1},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1af8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainAndValidate2(model, model_output_path, model_path):\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=TrainingArguments(\n",
    "#             output_dir=model_output_path,\n",
    "#             # Set the learning rate\n",
    "#             learning_rate=2e-5,\n",
    "#             # Set the per device train batch size and eval batch size\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             # Evaluate and save the model after each epoch\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             # eval_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             num_train_epochs=train_epochs,\n",
    "#             weight_decay=0.01,\n",
    "#             load_best_model_at_end=True,\n",
    "#         ),\n",
    "#         train_dataset=tokenized_dataset[\"train\"],\n",
    "#         eval_dataset=tokenized_dataset[\"test\"],\n",
    "#         tokenizer=tokenizer,\n",
    "#         data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "#         compute_metrics=compute_metrics,\n",
    "#     )\n",
    "\n",
    "#     trainer.train()\n",
    "    \n",
    "    \n",
    "#     model.to(device)\n",
    "#     trainer.evaluate()\n",
    "    \n",
    "#     model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb565e",
   "metadata": {},
   "source": [
    "## Apply LoRA(PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17fd504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qlora_model = get_peft_model(qlora_model, lora_config)\n",
    "\n",
    "# qlora_model.print_trainable_parameters()\n",
    "\n",
    "# qlora_trainer = TrainAndValidate2(qlora_model, qlora_model_output_path, qlora_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7616ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, tokenizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i : i + batch_size]\n",
    "\n",
    "        # Tokenize this batch of text dynamically with padding + truncation\n",
    "        inputs = tokenizer(\n",
    "            batch[\"sms\"],\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=128\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        preds += torch.argmax(outputs.logits, dim=1).cpu().tolist()\n",
    "        labels += batch[\"label\"]\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f4f4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset=tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_acc, foundation_f1 = evaluate_model(foundation_model, eval_dataset, tokenizer)\n",
    "lora_acc, lora_f1 = evaluate_model(lora_model, eval_dataset, tokenizer)\n",
    "# qlora_acc, qlora_f1 = evaluate_model(qlora_model, eval_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundation Model - Accuracy: 0.9883, F1: 0.9547\n",
      "Lora Model - Accuracy: 0.9883, F1: 0.9547\n"
     ]
    }
   ],
   "source": [
    "print(f\"Foundation Model - Accuracy: {foundation_acc:.4f}, F1: {foundation_f1:.4f}\")\n",
    "print(f\"Lora Model - Accuracy: {lora_acc:.4f}, F1: {lora_f1:.4f}\")\n",
    "# # print(f\"Qlora Model - Accuracy: {qlora_acc:.4f}, F1: {qlora_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b70a9e",
   "metadata": {},
   "source": [
    "## Zip output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67a33d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./tmp/archive.zip' created successfully from './tmp/training_artifacts'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_dir = os.path.join(root_dir, training_artifacts_dir)\n",
    "archive_name = os.path.join(root_dir, archive_zip)\n",
    "# Create the zip archive\n",
    "shutil.make_archive(archive_name, 'zip', source_dir)\n",
    "\n",
    "print(f\"'{archive_name}.zip' created successfully from '{source_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198b8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
