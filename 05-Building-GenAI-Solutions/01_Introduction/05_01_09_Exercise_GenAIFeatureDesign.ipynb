{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are tasked with creating an application that aggregates and summarizes restaurant reviews. Users will provide the name of a restaurant and the type of cuisine, and the application will generate a summary of the most prevalent sentiments found in online reviews for that specific restaurant and cuisine type.\n",
    "\n",
    "**Challenge** \n",
    "\n",
    "Develop a prompt template that guides the LLM to generate a concise, sentiment-focused summary based on user inputs: the restaurant name and the type of cuisine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand the User Inputs**\n",
    "\n",
    "Identify the essential user inputs for this task. In this scenario, you need:\n",
    "- Restaurant Name\n",
    "- Cuisine Type\n",
    "- Can you think of others to make your prompt more specific or flexible? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables to store the user inputs\n",
    "restaurant_name = \"Alinea\"\n",
    "cuisine_type = \"new american\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Craft the Prompt**\n",
    "\n",
    "Compose a clear, concise instruction that will direct the LLM to generate a sentiment-focused summary for the specified restaurant and cuisine.\n",
    " - The prompt should be specific enough to guide the LLM towards the desired output \n",
    " - But also flexible enough to handle a range of restaurants and cuisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Provide a summary of customer sentiments for Alinea, focusing on their new american dishes. Highlight key sentiments and mention any standout dishes or services. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Prompt Template**\n",
    "\n",
    "Design a template that integrates the user inputs into the LLM prompt.\n",
    "Use brackets {} to denote where the user inputs should be placed. This makes the template dynamic, allowing for different restaurant names and cuisine types to be inserted into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide a summary of customer sentiments for Alinea, focusing on their new american dishes. Highlight key sentiments and mention any standout dishes or services. \n"
     ]
    }
   ],
   "source": [
    "prompt_template = f\"Provide a summary of customer sentiments for {restaurant_name}, focusing on their {cuisine_type} dishes. Highlight key sentiments and mention any standout dishes or services. \"\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call the OpenAI GPT-3.5 API with your prompt and see how the model responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the OpenAI API with your prompt and print the response\n",
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "# openAI API key\n",
    "api_key = \"openAI_API_key\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated review:\n",
      "Alinea, known for its innovative and creative New American cuisine, has garnered impressive customer sentiments for its unique and impeccable dishes. Customers have raved about the restaurant's bold and adventurous flavor combinations, as well as its exquisite presentation. Standout dishes that have received high praise include the deconstructed lobster pot pie and the whimsical edible balloon dessert. The service at Alinea has also been commended for its attentiveness and knowledge of the menu, enhancing the overall dining experience for patrons. Overall, customers have expressed delight and satisfaction with Alinea's New American offerings, making it a must-visit destination for food enthusiasts.\n"
     ]
    }
   ],
   "source": [
    "# Function to call the OpenAI GPT-3.5 API\n",
    "def generatge_restaurant_review(prompt_template):\n",
    "    try:\n",
    "        # Calling the OpenAI API with a system message and our prompt in the user message content\n",
    "        # Use openai.ChatCompletion.create for openai < 1.0\n",
    "        # openai.chat.completions.create for openai > 1.0\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turob\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a restaurant critic. You are writing about reviews of restaurants. \"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt_template\n",
    "            }\n",
    "        ],\n",
    "            temparature=1,\n",
    "            max_tokens=256,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        # The response is a JSPOM object containing more information than the generated reivew. We want to return only the message content\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "    \n",
    "# Generating the response from the model\n",
    "review_summary = generate_restaurant_review(prompt_template)\n",
    "\n",
    "# Printing the output.\n",
    "print(\"Generated review:\")\n",
    "print(review_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
